# ğŸ³ Cally Docker Deployment Guide

This guide covers deploying Cally using Docker containers for easier management, isolation, and consistency across environments.

## ğŸ¯ Why Docker?

- **âœ… Consistent Environment**: Same environment everywhere (dev, staging, production)
- **âœ… Easy Dependency Management**: No more RVM, Ruby version, or gem conflicts
- **âœ… Resource Isolation**: Ollama AI and Rails run in separate containers
- **âœ… Simple Updates**: Pull new images and restart containers
- **âœ… Auto-scaling**: Easy to scale with load balancers
- **âœ… Health Monitoring**: Built-in health checks for all services

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Nginx       â”‚â”€â”€â”€â”€â”‚   Cally Rails   â”‚â”€â”€â”€â”€â”‚     Ollama      â”‚
â”‚   (Port 80)     â”‚    â”‚   (Port 3000)   â”‚    â”‚  (Port 11434)   â”‚
â”‚  Load Balancer  â”‚    â”‚  Web Applicationâ”‚    â”‚   AI Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requirements

### ğŸ’» Local Machine:
- Docker & Docker Compose
- `sshpass` (for automated deployment)

### ğŸŒ DigitalOcean Droplet:
- **Minimum**: 2GB RAM, 1 vCPU ($12/month)
- **Recommended**: 4GB RAM, 2 vCPU ($24/month) for better AI performance
- Ubuntu 22.04 LTS

## ğŸš€ Quick Deployment

### Option 1: One-Command Deployment
```bash
./deploy_docker.sh 157.230.142.228 your_server_password
```

### Option 2: Manual Steps

1. **Upload to server:**
```bash
tar --exclude='.git' --exclude='storage/*.sqlite3' -czf cally-docker.tar.gz .
scp cally-docker.tar.gz root@YOUR_IP:/tmp/
```

2. **Deploy on server:**
```bash
ssh root@YOUR_IP
cd /opt && mkdir cally-docker && cd cally-docker
tar -xzf /tmp/cally-docker.tar.gz
docker-compose -f docker-compose.production.yml up --build -d
```

## ğŸ”§ Docker Services

### ğŸ¤– Ollama (AI Service)
- **Image**: `ollama/ollama:latest`
- **Memory**: 1.5GB limit, 512MB reserved
- **Models**: qwen2.5:0.5b (optimized for 2GB servers)
- **Port**: 11434 (internal only)
- **Health Check**: API version endpoint

### ğŸš‚ Cally Rails App
- **Build**: Custom Dockerfile with Ruby 3.4.1
- **Memory**: 512MB limit, 256MB reserved  
- **Port**: 3000 (internal only)
- **Environment**: Production with optimizations
- **Health Check**: `/health` endpoint

### ğŸŒ Nginx (Load Balancer)
- **Image**: `nginx:alpine`
- **Port**: 80 (public)
- **Features**: Rate limiting, compression, static asset caching
- **Proxy**: Routes traffic to Cally app

## ğŸ› ï¸ Management Commands

### View Real-time Logs:
```bash
cd /opt/cally-docker
docker-compose -f docker-compose.production.yml logs -f
```

### Restart Services:
```bash
systemctl restart cally-docker
# OR
docker-compose -f docker-compose.production.yml restart
```

### Update Cally:
```bash
cd /opt/cally-docker
git pull origin main
docker-compose -f docker-compose.production.yml up --build -d
```

### Check Status:
```bash
docker-compose -f docker-compose.production.yml ps
systemctl status cally-docker
```

### Access Containers:
```bash
# Rails console
docker exec -it cally-app rails console

# Ollama shell
docker exec -it cally-ollama bash

# Test AI directly
docker exec cally-ollama ollama run qwen2.5:0.5b "Hello!"
```

## ğŸ” Troubleshooting

### Container Won't Start:
```bash
docker-compose -f docker-compose.production.yml logs service_name
```

### AI Model Issues:
```bash
# Check available models
docker exec cally-ollama ollama list

# Pull model manually
docker exec cally-ollama ollama pull qwen2.5:0.5b

# Test model
docker exec cally-ollama ollama run qwen2.5:0.5b "test"
```

### Memory Issues:
```bash
# Check container resource usage
docker stats

# Check server memory
free -h
```

### Reset Everything:
```bash
cd /opt/cally-docker
docker-compose -f docker-compose.production.yml down -v
docker system prune -a
docker-compose -f docker-compose.production.yml up --build -d
```

## ğŸ“Š Resource Usage

| Service | Memory | CPU | Storage |
|---------|--------|-----|---------|
| Ollama  | ~1GB   | 50% | 2GB (models) |
| Cally   | ~200MB | 20% | 100MB |
| Nginx   | ~10MB  | 5%  | 50MB |
| **Total** | **~1.2GB** | **75%** | **~2.2GB** |

## ğŸ”’ Security Features

- **Non-root containers**: All services run as non-root users
- **Network isolation**: Services communicate via Docker network
- **Rate limiting**: Nginx prevents API abuse
- **Health checks**: Automatic restart of failed services
- **Resource limits**: Prevents containers from consuming all memory

## ğŸŒŸ Benefits over Manual Deployment

| Manual Deployment | Docker Deployment |
|-------------------|-------------------|
| Complex Ruby/RVM setup | âœ… Pre-built Ruby environment |
| Manual service management | âœ… Auto-restart with systemd |
| Dependency conflicts | âœ… Isolated containers |
| Manual backup/restore | âœ… Volume management |
| Difficult scaling | âœ… Easy horizontal scaling |
| Hard to update | âœ… Simple image updates |

## ğŸ’° Cost Optimization

**Recommended DigitalOcean setup:**
- **$12/month** (2GB RAM) - Perfect for light usage
- **$24/month** (4GB RAM) - Better for heavier usage
- Add **monitoring** ($6/month) for production alerts

## ğŸ”„ Auto-Updates

Set up automatic updates with cron:
```bash
# Add to crontab: crontab -e
0 3 * * 0 cd /opt/cally-docker && git pull && docker-compose -f docker-compose.production.yml up --build -d
```

## ğŸ‰ Success!

Once deployed, your Cally AI assistant will be:
- ğŸŒ **Accessible** at your server IP
- ğŸ¤– **AI-powered** with kid-friendly responses  
- ğŸ”„ **Auto-restarting** if services fail
- ğŸ“ˆ **Monitored** with health checks
- ğŸ›¡ï¸ **Secure** with proper isolation

Perfect for kids to safely chat with their AI friend! ğŸš€
